{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolai5965/Predictive_Text_Generation_with_LSTM_model/blob/main/Predictive_Text_Generation_with_LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5wsYlOd58kKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d99dc4e-22fc-4ecf-9141-d54cdd6e79f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import words\n",
        "\n",
        "# Download the words corpus if you haven't done so already\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "# Mount Google Drive to load the dataset\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3HWBugcZh3L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xpRhPB2sirBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28c977e-463e-46a4-a54d-858253441e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 19 05:21:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0915PQSKisxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09daa072-48fc-463c-f9c6-511e7ab10d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zszVsFGO8tua"
      },
      "outputs": [],
      "source": [
        "# Define the file path and load the train and test data\n",
        "filepath = '/content/drive/My Drive/Colab Notebooks/Machine Learning/TensorFlow/GRU/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_mwPutS86lU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'{filepath}fake_or_real_news.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2Rb_jzt68-Nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ff456132-ad30-41eb-ca45-ca8050675328"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         id                                              title  \\\n",
              "0      8476                       You Can Smell Hillary’s Fear   \n",
              "1     10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
              "2      3608        Kerry to go to Paris in gesture of sympathy   \n",
              "3     10142  Bernie supporters on Twitter erupt in anger ag...   \n",
              "4       875   The Battle of New York: Why This Primary Matters   \n",
              "...     ...                                                ...   \n",
              "6330   4490  State Department says it can't find emails fro...   \n",
              "6331   8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
              "6332   8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
              "6333   4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
              "6334   4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
              "\n",
              "                                                   text label  \n",
              "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
              "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
              "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
              "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
              "4     It's primary day in New York and front-runners...  REAL  \n",
              "...                                                 ...   ...  \n",
              "6330  The State Department told the Republican Natio...  REAL  \n",
              "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
              "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
              "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
              "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
              "\n",
              "[6335 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a1ebe2c-e9e9-4a87-9dbc-f85cbbdc5d06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>4490</td>\n",
              "      <td>State Department says it can't find emails fro...</td>\n",
              "      <td>The State Department told the Republican Natio...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6331</th>\n",
              "      <td>8062</td>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6332</th>\n",
              "      <td>8622</td>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>4021</td>\n",
              "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
              "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6334</th>\n",
              "      <td>4330</td>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6335 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a1ebe2c-e9e9-4a87-9dbc-f85cbbdc5d06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a1ebe2c-e9e9-4a87-9dbc-f85cbbdc5d06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a1ebe2c-e9e9-4a87-9dbc-f85cbbdc5d06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text_data(df, column_name, data_proportion, test_size, fixed_sequence_len, fixed_n_gram_len):\n",
        "    # Extract text data\n",
        "    text = list(df[column_name].values)\n",
        "\n",
        "    # Determine the number of samples to use\n",
        "    num_samples = int(len(text) * data_proportion)\n",
        "\n",
        "    # Use only the specified proportion of samples\n",
        "    text = text[:num_samples]\n",
        "\n",
        "    # Lowercasing: Convert all text to lowercase.\n",
        "    text = [t.lower() for t in text]\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_text, val_text = train_test_split(text, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Define tokenizer\n",
        "    tokenizer = Tokenizer()\n",
        "\n",
        "    # Fit tokenizer on training text data\n",
        "    tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "    # Total number of words before removal\n",
        "    total_words_before_removal = len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Remove words that are not recognized as English words\n",
        "    english_words = set(words.words())\n",
        "    tokenizer.word_index = {word: index for word, index in tokenizer.word_index.items() if word in english_words}\n",
        "    removed_words = list(set(tokenizer.word_index.keys()) - english_words)\n",
        "\n",
        "    # Update total_words after removal\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Function to convert text data to sequence of tokens\n",
        "    def text_to_sequences(text_data):\n",
        "        input_sequences = []\n",
        "        for line in text_data:\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            for i in range(0, len(token_list) - fixed_n_gram_len + 1):\n",
        "                n_gram_sequence = token_list[i:i + fixed_n_gram_len]\n",
        "                input_sequences.append(n_gram_sequence)\n",
        "        return input_sequences\n",
        "\n",
        "    # Convert training and validation text data to sequences\n",
        "    train_sequences = text_to_sequences(train_text)\n",
        "    val_sequences = text_to_sequences(val_text)\n",
        "\n",
        "    # Pad sequences\n",
        "    train_sequences = np.array(pad_sequences(train_sequences, maxlen=fixed_sequence_len, padding='pre'))\n",
        "    val_sequences = np.array(pad_sequences(val_sequences, maxlen=fixed_sequence_len, padding='pre'))\n",
        "\n",
        "    # Create predictors and labels for both training and validation sets\n",
        "    train_x, train_y = train_sequences[:, :-1], train_sequences[:, -1]\n",
        "    val_x, val_y = val_sequences[:, :-1], val_sequences[:, -1]\n",
        "\n",
        "    # Convert to numpy array and set out-of-range indices to 0\n",
        "    train_y, val_y = np.array(train_y), np.array(val_y)\n",
        "    train_y[train_y >= total_words], val_y[val_y >= total_words] = 0, 0\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    train_y = tf.keras.utils.to_categorical(train_y, num_classes=total_words)\n",
        "    val_y = tf.keras.utils.to_categorical(val_y, num_classes=total_words)\n",
        "\n",
        "    return (train_x, train_y), (val_x, val_y), total_words, tokenizer, removed_words"
      ],
      "metadata": {
        "id": "C13Ennlf9rX5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e3cCmu67XyHL"
      },
      "outputs": [],
      "source": [
        "# Custom LSTM cell\n",
        "class LSTMCell(Layer):\n",
        "    # Initialize LSTM cell with given parameters\n",
        "    def __init__(self, units, activation='tanh', recurrent_activation='sigmoid', kernel_regularizer=None, recurrent_regularizer=None, **kwargs):\n",
        "        super(LSTMCell, self).__init__(**kwargs)\n",
        "        self.units = units # Number of LSTM units\n",
        "        self.activation = tf.keras.activations.get(activation) # Activation function for cell state\n",
        "        self.recurrent_activation = tf.keras.activations.get(recurrent_activation) # Activation function for gates\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer) # Regularizer function applied to the input weights\n",
        "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)  # Regularizer function applied to the recurrent weights\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Input gate weights\n",
        "        self.kernel_i = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                        initializer='glorot_uniform',\n",
        "                                        name='kernel_i',\n",
        "                                        regularizer=self.kernel_regularizer)\n",
        "        self.recurrent_kernel_i = self.add_weight(shape=(self.units, self.units),\n",
        "                                                  initializer='orthogonal',\n",
        "                                                  name='recurrent_kernel_i',\n",
        "                                                  regularizer=self.recurrent_regularizer)\n",
        "        self.bias_i = self.add_weight(shape=(self.units,), initializer='zeros', name='bias_i')\n",
        "        # Forget gate weights\n",
        "        self.kernel_f = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                        initializer='glorot_uniform',\n",
        "                                        name='kernel_f',\n",
        "                                        regularizer=self.kernel_regularizer)\n",
        "        self.recurrent_kernel_f = self.add_weight(shape=(self.units, self.units),\n",
        "                                                  initializer='orthogonal',\n",
        "                                                  name='recurrent_kernel_f',\n",
        "                                                  regularizer=self.recurrent_regularizer)\n",
        "        self.bias_f = self.add_weight(shape=(self.units,), initializer='zeros', name='bias_f')\n",
        "        # Cell state weights\n",
        "        self.kernel_c = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                        initializer='glorot_uniform',\n",
        "                                        name='kernel_c',\n",
        "                                        regularizer=self.kernel_regularizer)\n",
        "        self.recurrent_kernel_c = self.add_weight(shape=(self.units, self.units),\n",
        "                                                  initializer='orthogonal',\n",
        "                                                  name='recurrent_kernel_c',\n",
        "                                                  regularizer=self.recurrent_regularizer)\n",
        "        self.bias_c = self.add_weight(shape=(self.units,), initializer='zeros', name='bias_c')\n",
        "        # Output gate weights\n",
        "        self.kernel_o = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                        initializer='glorot_uniform',\n",
        "                                        name='kernel_o',\n",
        "                                        regularizer=self.kernel_regularizer)\n",
        "        self.recurrent_kernel_o = self.add_weight(shape=(self.units, self.units),\n",
        "                                                  initializer='orthogonal',\n",
        "                                                  name='recurrent_kernel_o',\n",
        "                                                  regularizer=self.recurrent_regularizer)\n",
        "        self.bias_o = self.add_weight(shape=(self.units,), initializer='zeros', name='bias_o')\n",
        "\n",
        "        self.built = True # Set built to True after weights initialization\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        prev_cell_state = states[1]\n",
        "\n",
        "        # Input gate calculation\n",
        "        i = self.recurrent_activation(tf.matmul(inputs, self.kernel_i) + tf.matmul(prev_output, self.recurrent_kernel_i) + self.bias_i) # The input gate decides how much of the new information from the current input should be stored in the cell state. It uses a sigmoid activation function to squash the values between 0 and 1, with 0 meaning \"store nothing\" and 1 meaning \"store everything\".\n",
        "\n",
        "        # Forget gate calculation\n",
        "        f = self.recurrent_activation(tf.matmul(inputs, self.kernel_f) + tf.matmul(prev_output, self.recurrent_kernel_f) + self.bias_f) # The forget gate decides how much of the past cell state should be forgotten or erased. It also uses a sigmoid activation function, with 0 meaning \"forget everything\" and 1 meaning \"forget nothing\".\n",
        "\n",
        "        # Cell state candidate\n",
        "        c_candidate = self.activation(tf.matmul(inputs, self.kernel_c) + tf.matmul(prev_output, self.recurrent_kernel_c) + self.bias_c) # This is a candidate for values that could be added to the cell state. It is created by applying a tanh activation function to the current input and the previous hidden state, squashing the values between -1 and 1.\n",
        "\n",
        "        # Cell state update\n",
        "        c = f * prev_cell_state + i * c_candidate # The cell state is updated by a combination of the forget gate, the previous cell state, the input gate, and the cell state candidate. The forget gate decides what to forget from the previous cell state, and the input gate decides what to add from the current cell state candidate.\n",
        "\n",
        "        # Output gate calculation\n",
        "        o = self.recurrent_activation(tf.matmul(inputs, self.kernel_o) + tf.matmul(prev_output, self.recurrent_kernel_o) + self.bias_o) # The output gate decides what the next hidden state should be. This is the output that will be used for predictions and will be passed to the next time step. It uses a sigmoid activation function to decide which parts of the cell state make it to the output.\n",
        "\n",
        "        # Final output calculation\n",
        "        output = o * self.activation(c) # The final output, also known as the hidden state, is computed as a combination of the output gate and the updated cell state passed through a tanh activation function. This output will be used for predictions and will be passed to the LSTM cell in the next time step.\n",
        "\n",
        "        return output, [output, c]\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        # Get the batch size from the shape of the inputs\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Return a list of two zero tensors with shape [batch_size, self.units]\n",
        "        # The first tensor represents the initial hidden state\n",
        "        # The second tensor represents the initial cell state\n",
        "        return [tf.zeros([batch_size, self.units], dtype=inputs.dtype), tf.zeros([batch_size, self.units], dtype=inputs.dtype)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "23K3cQLe-iNs"
      },
      "outputs": [],
      "source": [
        "# Custom LSTM layer\n",
        "class LSTM(Layer):\n",
        "    # Initialize LSTM layer with cell, return_sequences and return_state parameters\n",
        "    def __init__(self, cell, return_sequences=False, return_state=False, **kwargs):\n",
        "        super(LSTM, self).__init__(**kwargs)\n",
        "        self.cell = cell # LSTM cell\n",
        "        self.return_sequences = return_sequences # Boolean to determine if output at all steps should be returned\n",
        "        self.return_state = return_state # Boolean to determine if the last state should be returned\n",
        "\n",
        "    # Define the computation during the layer call\n",
        "    def call(self, inputs):\n",
        "        # Get the initial state from the LSTM cell\n",
        "        initial_state = self.cell.get_initial_state(inputs)\n",
        "        states = initial_state\n",
        "\n",
        "        # Initialize list to store outputs at each time step\n",
        "        outputs = []\n",
        "        for t in range(inputs.shape[1]):\n",
        "            input_t = inputs[:, t] # Input at time step t\n",
        "            output, states = self.cell(input_t, states) # Output and states at time step t\n",
        "            outputs.append(output)\n",
        "\n",
        "        # Stack the outputs from all time steps along the time axis\n",
        "        outputs = tf.stack(outputs, axis=1)\n",
        "        # Return outputs and states based on the return_sequences and return_state attributes\n",
        "        if self.return_sequences:\n",
        "            if self.return_state:\n",
        "                return outputs, states # Return outputs at all time steps and the final states\n",
        "            else:\n",
        "                return outputs # Return outputs at all time steps\n",
        "        else:\n",
        "            if self.return_state:\n",
        "                return outputs[:, -1], states # Return output at last time step and the final states\n",
        "            else:\n",
        "                return outputs[:, -1] # Return output at last time step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aamvUF0s-gc7"
      },
      "outputs": [],
      "source": [
        "class Model(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, hidden_units, max_features, l2_reg):\n",
        "        super(Model, self).__init__() # Call the parent class initializer\n",
        "        self.embedding = Embedding(input_dim=max_features, output_dim=embedding_dim) # Define the embedding layer\n",
        "        self.lstm_cell = LSTMCell(units=hidden_units, kernel_regularizer=regularizers.l2(l2_reg), recurrent_regularizer=regularizers.l2(l2_reg)) # Define the LSTM cell\n",
        "        self.lstm = LSTM(self.lstm_cell, return_sequences=False) # Define the LSTM layer\n",
        "        self.dense = Dense(max_features, activation='softmax') # Define the output layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs) # Pass the input through the embedding layer\n",
        "        x = self.lstm(x) # Pass the output of the embedding layer through the LSTM layer\n",
        "        return self.dense(x) # Pass the output of the LSTM layer through the output layer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing configuration\n",
        "preprocessing_config = {\n",
        "    'data_proportion': 0.04,\n",
        "    'text_split_size': 0.2,\n",
        "    'fixed_sequence_len': 25,\n",
        "    'fixed_n_gram_len': 20\n",
        "}\n"
      ],
      "metadata": {
        "id": "tSGyrQ0DsBv_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the text data\n",
        "(train_x, train_y), (val_x, val_y), total_words, tokenizer, removed_words = prepare_text_data(df, \n",
        "                                                                    'text', \n",
        "                                                                    preprocessing_config['data_proportion'], \n",
        "                                                                    preprocessing_config['text_split_size'],\n",
        "                                                                    preprocessing_config['fixed_sequence_len'], \n",
        "                                                                    preprocessing_config['fixed_n_gram_len'])"
      ],
      "metadata": {
        "id": "Q566XdaysQCJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display shape of predictors and label\n",
        "print(\"Train Predictors shape:\", train_x.shape)\n",
        "print(\"Train Label shape:\", train_y.shape)\n",
        "print(\"Validation Predictors shape:\", val_x.shape)\n",
        "print(\"Validation Label shape:\", val_y.shape)\n",
        "\n",
        "# Display an example predictor and label\n",
        "print(\"Example Predictor:\", train_x[0])\n",
        "print(\"Example Label:\", train_y[0])\n",
        "\n",
        "# Display the total number of unique words\n",
        "print(\"Total number of unique words:\", total_words)\n",
        "\n",
        "# Output removed words\n",
        "if len(removed_words) > 0:\n",
        "    print(\"Number of words removed:\", len(removed_words))\n",
        "    print(\"Removed words:\", removed_words)\n",
        "else:\n",
        "    print(\"No words were removed.\")"
      ],
      "metadata": {
        "id": "cOpj0bBJsMF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5902e93-5f79-4802-9c51-4b14d2da46de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Predictors shape: (111441, 24)\n",
            "Train Label shape: (111441, 7324)\n",
            "Validation Predictors shape: (34092, 24)\n",
            "Validation Label shape: (34092, 7324)\n",
            "Example Predictor: [   0    0    0    0    0 3535 2662  513   19    5  996  550 1493   31\n",
            " 2663    4   44  531  295   74  996 1393   17    8]\n",
            "Example Label: [0. 0. 0. ... 0. 0. 0.]\n",
            "Total number of unique words: 7324\n",
            "No words were removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display distribution of sequence lengths\n",
        "sequence_lengths = [len(seq) for seq in np.concatenate([train_x, val_x])]\n",
        "plt.hist(sequence_lengths, bins=30)\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Get word counts\n",
        "word_counts = tokenizer.word_counts\n",
        "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display most common and least common words\n",
        "print(\"10 most common words:\", sorted_word_counts[:10])\n",
        "print(\"10 least common words:\", sorted_word_counts[-10:])\n",
        "\n",
        "# Count and display number of words that appear only once\n",
        "single_appearance_words = len([count for word, count in word_counts.items() if count == 1])\n",
        "print(\"Number of words that appear only once:\", single_appearance_words)\n",
        "\n",
        "# Display example of original text and its tokenized equivalent\n",
        "example_text = df['text'][0]  # As the original text isn't directly returned by the function anymore\n",
        "example_tokens = tokenizer.texts_to_sequences([example_text])[0]\n",
        "print(\"Example original text:\", example_text[:20])\n",
        "print(\"Example tokenized text:\", example_tokens[:20])\n"
      ],
      "metadata": {
        "id": "h7GVRFrEuHxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "40debac4-877b-4b6f-9fe5-d563cff5c2a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 most common words: [('the', 8282), ('to', 4266), ('of', 3710), ('and', 3592), ('a', 3198), ('in', 2955), ('that', 1995), ('is', 1515), ('on', 1361), ('for', 1306)]\n",
            "10 least common words: [('tick', 1), ('tock', 1), ('“they’ve', 1), ('bernie’s', 1), ('roseann', 1), ('demoro', 1), ('185', 1), ('dean', 1), ('88', 1), ('endorsing', 1)]\n",
            "Number of words that appear only once: 7074\n",
            "Example original text: Daniel Greenfield, a\n",
            "Example tokenized text: [5, 2716, 1088, 25, 1, 523, 410, 8, 5, 54, 188, 2700, 9, 2844, 6, 1, 757, 1105, 3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model configuration\n",
        "model_config = {\n",
        "    'embedding_dim': 100,\n",
        "    'hidden_units': 32,\n",
        "    'max_features': total_words,\n",
        "    'l2_reg': 1e-4,\n",
        "    'optimizer': 'RMSprop',\n",
        "    'learning_rate': 0.01,\n",
        "    'loss': 'categorical_crossentropy',\n",
        "    'metrics': ['accuracy'],\n",
        "    'batch_size': 256,\n",
        "    'epochs': 10,\n",
        "    'validation_split': 0.2,\n",
        "    'patience': 5,\n",
        "    'verbose': 2\n",
        "}"
      ],
      "metadata": {
        "id": "zzd10bFVINHX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the model\n",
        "model = Model(model_config['embedding_dim'], model_config['hidden_units'], model_config['max_features'], model_config['l2_reg'])\n",
        "model.compile(optimizer=RMSprop(learning_rate=model_config['learning_rate']), \n",
        "              loss=model_config['loss'], \n",
        "              metrics=model_config['metrics'])\n",
        "\n",
        "# Define the early stopping callback with the desired parameters\n",
        "early_stopping = EarlyStopping(monitor='val_loss', \n",
        "                               patience=model_config['patience'], \n",
        "                               restore_best_weights=True)\n",
        "\n",
        "# Specify the path where you want to save the model\n",
        "checkpoint_filepath = '/content/drive/My Drive/Colab Notebooks/Machine Learning/TensorFlow/LSTM/LSTM_best_model_callback/'\n",
        "\n",
        "# Create a ModelCheckpoint callback that saves the weights only during training\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n"
      ],
      "metadata": {
        "id": "jr6c-xQ1sFC6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_x, \n",
        "                    train_y, \n",
        "                    epochs=model_config['epochs'], \n",
        "                    batch_size=model_config['batch_size'], \n",
        "                    validation_data=(val_x, val_y), \n",
        "                    callbacks=[early_stopping, model_checkpoint_callback], \n",
        "                    verbose=model_config['verbose'])"
      ],
      "metadata": {
        "id": "c3Yf7YYhwjNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eeb76e-e7e0-40d6-ae37-5a3796677f93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "436/436 - 53s - loss: 6.2470 - accuracy: 0.0874 - val_loss: 6.1477 - val_accuracy: 0.0965 - 53s/epoch - 121ms/step\n",
            "Epoch 2/10\n",
            "436/436 - 14s - loss: 5.9083 - accuracy: 0.1170 - val_loss: 5.9423 - val_accuracy: 0.1080 - 14s/epoch - 33ms/step\n",
            "Epoch 3/10\n",
            "436/436 - 15s - loss: 5.7793 - accuracy: 0.1267 - val_loss: 5.8944 - val_accuracy: 0.1180 - 15s/epoch - 35ms/step\n",
            "Epoch 4/10\n",
            "436/436 - 14s - loss: 5.6977 - accuracy: 0.1332 - val_loss: 5.8848 - val_accuracy: 0.1167 - 14s/epoch - 32ms/step\n",
            "Epoch 5/10\n",
            "436/436 - 14s - loss: 5.6295 - accuracy: 0.1386 - val_loss: 5.8513 - val_accuracy: 0.1227 - 14s/epoch - 33ms/step\n",
            "Epoch 6/10\n",
            "436/436 - 15s - loss: 5.5726 - accuracy: 0.1424 - val_loss: 5.8636 - val_accuracy: 0.1214 - 15s/epoch - 34ms/step\n",
            "Epoch 7/10\n",
            "436/436 - 14s - loss: 5.5210 - accuracy: 0.1469 - val_loss: 5.8586 - val_accuracy: 0.1222 - 14s/epoch - 32ms/step\n",
            "Epoch 8/10\n",
            "436/436 - 13s - loss: 5.4725 - accuracy: 0.1513 - val_loss: 5.8327 - val_accuracy: 0.1244 - 13s/epoch - 31ms/step\n",
            "Epoch 9/10\n",
            "436/436 - 14s - loss: 5.4281 - accuracy: 0.1549 - val_loss: 5.8423 - val_accuracy: 0.1255 - 14s/epoch - 32ms/step\n",
            "Epoch 10/10\n",
            "436/436 - 19s - loss: 5.3859 - accuracy: 0.1590 - val_loss: 5.8412 - val_accuracy: 0.1282 - 19s/epoch - 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(model.summary())"
      ],
      "metadata": {
        "id": "uRwufawOAxbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "876797db-e7b9-49ad-b947-a88ea935fda4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  732400    \n",
            "                                                                 \n",
            " lstm_cell (LSTMCell)        multiple                  17024     \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  17024     \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  241692    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,116\n",
            "Trainable params: 991,116\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pAJo31sWHAQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "cdbda928-a65c-4c7e-937b-834b8c31bf2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Word Likelihood\n",
              "0    be     22.85%\n",
              "1   not     13.15%\n",
              "2  have      2.46%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e550de1-5da4-40f1-ad37-426bfe391a45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be</td>\n",
              "      <td>22.85%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not</td>\n",
              "      <td>13.15%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>have</td>\n",
              "      <td>2.46%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e550de1-5da4-40f1-ad37-426bfe391a45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e550de1-5da4-40f1-ad37-426bfe391a45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e550de1-5da4-40f1-ad37-426bfe391a45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Word Likelihood\n",
              "0   be      9.39%\n",
              "1  the      4.14%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abae5cca-bb3b-419d-8d13-ab2814684061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be</td>\n",
              "      <td>9.39%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the</td>\n",
              "      <td>4.14%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abae5cca-bb3b-419d-8d13-ab2814684061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abae5cca-bb3b-419d-8d13-ab2814684061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abae5cca-bb3b-419d-8d13-ab2814684061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Word Likelihood\n",
              "0   are     16.65%\n",
              "1  have     15.77%\n",
              "2  will      5.39%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dff27a4-8bf3-49e1-9fd6-afbcb548b0ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>are</td>\n",
              "      <td>16.65%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>have</td>\n",
              "      <td>15.77%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>will</td>\n",
              "      <td>5.39%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dff27a4-8bf3-49e1-9fd6-afbcb548b0ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4dff27a4-8bf3-49e1-9fd6-afbcb548b0ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4dff27a4-8bf3-49e1-9fd6-afbcb548b0ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def predict_next_word(model, tokenizer, input_text, fixed_sequence_len, n_best=3):\n",
        "    # Tokenize the input text\n",
        "    input_tokens = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    # Pad the tokens\n",
        "    input_tokens = pad_sequences([input_tokens], maxlen=fixed_sequence_len-1, padding='pre')\n",
        "    # Predict the probabilities for the next word\n",
        "    probabilities = model.predict(input_tokens, verbose=0)\n",
        "    # Get the indices of the n_best most probable next words\n",
        "    top_indices = np.argpartition(probabilities[0], -n_best)[-n_best:]\n",
        "    # Get these indices sorted by probability\n",
        "    sorted_indices = top_indices[np.argsort(-probabilities[0][top_indices])]\n",
        "    # Reverse the word index\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
        "    # Filter valid indices\n",
        "    valid_indices = [i for i in sorted_indices if i in reverse_word_index and i != 0]  # <-- Modified line\n",
        "    # Look up the words corresponding to the valid indices\n",
        "    next_words = [reverse_word_index[i] for i in valid_indices]  # <-- Modified line\n",
        "    # Look up the probabilities corresponding to the valid indices\n",
        "    likelihoods = probabilities[0][valid_indices]  # <-- Modified line\n",
        "    # Create a DataFrame with the words and their likelihoods\n",
        "    df = pd.DataFrame({\n",
        "        'Word': next_words,\n",
        "        'Likelihood': [f\"{likelihood * 100:.2f}%\" for likelihood in likelihoods]\n",
        "    })\n",
        "    return df\n",
        "\n",
        "best_words = 3\n",
        "\n",
        "possible = predict_next_word(model, tokenizer, \"The economic outlook for the next year has been released and it suggests that the growth rate will\", preprocessing_config['fixed_sequence_len'])\n",
        "display(possible)\n",
        "possible = predict_next_word(model, tokenizer, \"In the world of artificial intelligence, recent advancements have led to a renewed interest in developing systems that can\", preprocessing_config['fixed_sequence_len'])\n",
        "display(possible)\n",
        "possible = predict_next_word(model, tokenizer, \"Climate change is having a dramatic effect on global weather patterns, and scientists are warning that if we don't\", preprocessing_config['fixed_sequence_len'])\n",
        "display(possible)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, input_text, fixed_sequence_len, n_words, creativity=3):\n",
        "    # Split the input text into a list of words\n",
        "    word_sequence = input_text.split()\n",
        "    # Generate the specified number of words\n",
        "    for _ in range(n_words):\n",
        "        sub_sequence = \" \".join(word_sequence[-fixed_sequence_len:])\n",
        "        try:\n",
        "            # Predict the next word based on the sub_sequence\n",
        "            predictions = predict_next_word(model, tokenizer, sub_sequence, fixed_sequence_len, n_best=creativity)\n",
        "            # Sort the predictions by likelihood\n",
        "            predictions.sort_values(by='Likelihood', ascending=False, inplace=True)\n",
        "            # Get the top 'creativity' predictions\n",
        "            top_predictions = predictions.head(creativity)['Word'].tolist()\n",
        "            # Randomly choose one of the top predictions\n",
        "            choice = random.choice(top_predictions)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {e}\")\n",
        "            choice = random.choice(word_sequence)\n",
        "        word_sequence.append(choice)\n",
        "    return \" \".join(word_sequence)\n",
        "\n",
        "# Define the input string\n",
        "input_string = \"The economic outlook for the next year has been released and it suggests that the growth rate will\"\n",
        "generated_text = generate_text(model, tokenizer, input_string, preprocessing_config['fixed_sequence_len'], n_words=100, creativity=3)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "uw_C4jKzCZQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62d4d7f-cd35-4b9f-b514-786f5082605e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economic outlook for the next year has been released and it suggests that the growth rate will not be the of the and of and that the only one in the of a more than a more than a lot in a more than the of and a lot of and the only of our country and the of a more and and the of a more and and the world the are the of a more and the world the are a lot in the only time in the of our country and the of a lot of the of the time of and i have been by the of a more and the of a\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrdP3Ui85R2ROA6vX4bSal",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}